{
  "distributed": false,
  "use_wandb": false,
  "wandb_project": "reasoning-under-uncertainty",

  "total_train_samples": 200000,
  "total_eval_samples": 1000,
  "batch_size": 1,
  "gradient_accumulation_steps": 64,
  "num_epochs": 1,
  "learning_rate": 5e-5,

  "model_name": "Qwen/Qwen2.5-7B-Instruct",

  "lora_r": 32,
  "lora_alpha": 16,
  "lora_dropout": 0.05,

  "causal_lm_ratio": 0.8,
  "use_zero": false,

  "dataset": "data/gsm8k/qwen",
  "threshold": 0.75,
  "datasets": [
    {
      "name": "gsm8k",
      "train_percentage": 1.0,
      "eval_percentage": 1.0
    }
  ],

  "output_dir": "outputs/loras/qwen"
}
